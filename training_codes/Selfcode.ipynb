{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1cc19f50702a476f93c1cb297e8be2a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfe8803fc5e54752a7877a7b2d838d7d","IPY_MODEL_f517996610d8410b9a7d64434fa053d1","IPY_MODEL_2bb42215b80a4d359280f5760a5633b3"],"layout":"IPY_MODEL_cd69305eb22743a49ed382e8050ba4c8"}},"bfe8803fc5e54752a7877a7b2d838d7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50e483f1a9be4d919057a3e9c7a09a88","placeholder":"​","style":"IPY_MODEL_2cc4d3a38f4f48b2b6f8af2bca7f6f2f","value":"100%"}},"f517996610d8410b9a7d64434fa053d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46f68a6cf09a4830ae51e79d73ccb985","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7005ed01404341fd998e5342f9728f3f","value":3}},"2bb42215b80a4d359280f5760a5633b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d175e0c7959a4855862f2be82dabfd8f","placeholder":"​","style":"IPY_MODEL_60281ceae94e44e7bb82875bee56e192","value":" 3/3 [00:00&lt;00:00, 113.06it/s]"}},"cd69305eb22743a49ed382e8050ba4c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50e483f1a9be4d919057a3e9c7a09a88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc4d3a38f4f48b2b6f8af2bca7f6f2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46f68a6cf09a4830ae51e79d73ccb985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7005ed01404341fd998e5342f9728f3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d175e0c7959a4855862f2be82dabfd8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60281ceae94e44e7bb82875bee56e192":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wcauZ3CgdXW","executionInfo":{"status":"ok","timestamp":1679477733318,"user_tz":-540,"elapsed":42659,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"a3587b99-c629-40e1-c81a-8f43a3afb438"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.13.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.13.2 transformers-4.27.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting einops\n","  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.6.0\n"]}],"source":["!pip install datasets\n","!pip install transformers\n","!pip install einops"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'deeplearning/'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lX1o6gKIAUcL","executionInfo":{"status":"ok","timestamp":1679477893333,"user_tz":-540,"elapsed":160019,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"3f9e77f2-b64c-4af6-9e55-3de3f5987119"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","['shortjokes.csv', 'openseminar_GAN.pptm', 'openseminar_GAN.pptm.gslides', 'Untitled0.ipynb', 'openseminar_GAN_final.docx', 'Davinci003.ipynb', 'Untitled', 'GPTNEO.ipynb', 'baseline.ipynb', 'RM_Training.ipynb', 'trained_models', 'Transformers.ipynb', 'QA_RL_PPO.ipynb', 'api.ipynb', 'RLHF_Dataset (1).ipynb', 'GPTNeoMyself.ipynb', 'InstructMyself2.ipynb', 'q-learning.ipynb', 'deepdai', 'VAE.ipynb', 'diffusion', 'competition', 'GPTNeo_RLHF.ipynb', 'CRS', 'reward_logs.txt', 'InstructMyself.ipynb']\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# Load all helpfulness/harmless subsets (share the same schema)\n","train_dataset = load_dataset(\"Anthropic/hh-rlhf\", split=\"train\")\n","test_dataset= load_dataset(\"Anthropic/hh-rlhf\", split=\"test\")\n","\n","dialogue_dataset = load_dataset(\"daily_dialog\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["1cc19f50702a476f93c1cb297e8be2a4","bfe8803fc5e54752a7877a7b2d838d7d","f517996610d8410b9a7d64434fa053d1","2bb42215b80a4d359280f5760a5633b3","cd69305eb22743a49ed382e8050ba4c8","50e483f1a9be4d919057a3e9c7a09a88","2cc4d3a38f4f48b2b6f8af2bca7f6f2f","46f68a6cf09a4830ae51e79d73ccb985","7005ed01404341fd998e5342f9728f3f","d175e0c7959a4855862f2be82dabfd8f","60281ceae94e44e7bb82875bee56e192"]},"id":"wAS_0h6IAgBc","executionInfo":{"status":"ok","timestamp":1679478768672,"user_tz":-540,"elapsed":1828,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"80cb4043-da68-47c6-c790-95c44e122e25"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n","WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/Anthropic___json/Anthropic--hh-rlhf-c8cd8dc58ab67414/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n","WARNING:datasets.builder:Found cached dataset daily_dialog (/root/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cc19f50702a476f93c1cb297e8be2a4"}},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from itertools import combinations\n","import io\n","import json\n","import os\n","import ast\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.distributions.categorical import Categorical\n","from tqdm import tqdm\n","\n","import transformers\n","from transformers import AutoTokenizer, BertForSequenceClassification\n","# from transformers import GPTNeoForCausalLM, GPT2Tokenizer, AdamW, get_scheduler, GPTNeoModel, GPT2LMHeadModel\n","import matplotlib.pyplot as plt\n","from collections import namedtuple, deque\n","from typing import List, Deque\n","from einops import rearrange"],"metadata":{"id":"EGT06Y1KA0bk","executionInfo":{"status":"ok","timestamp":1679478768672,"user_tz":-540,"elapsed":4,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["import logging\n","logging.getLogger().setLevel(logging.CRITICAL)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'"],"metadata":{"id":"jlCx0YYucjx9","executionInfo":{"status":"ok","timestamp":1679478768672,"user_tz":-540,"elapsed":4,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n","tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', padding_side=\"left\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","models_folder = \"trained_models\" # where to save model\n","\n","model.to(device)\n","print('skip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcBXdEDycp2P","executionInfo":{"status":"ok","timestamp":1679478770856,"user_tz":-540,"elapsed":2188,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"ff0a2feb-ce28-49d8-9875-012392903781"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["skip\n"]}]},{"cell_type":"code","source":["prompts=[\"Hello it's me.\"]"],"metadata":{"id":"7RMsIcIGtZ7t","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":5,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["tokenized=tokenizer(prompts, return_tensors='pt', truncation=True, padding=True) # tokenize 후 pytorch tensor를 return 하라는 뜻\n","print(\"ㄴ\")\n","input_ids, attention_mask = tokenized.input_ids.to(device), tokenized.attention_mask.to(device)\n","print(\"ㅇㅇ\", input_ids.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etatviTSsaBd","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":4,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"5a1d0ac4-1f84-4bde-8359-4f7b7bcafa61"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["ㄴ\n","ㅇㅇ torch.Size([1, 8])\n"]}]},{"cell_type":"code","source":["last_hidden_states=model(input_ids, attention_mask=attention_mask)"],"metadata":{"id":"VzYjZeL0tegY","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":3,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["last_hidden_states"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bu4pJV1_ti03","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":3,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"b0cddff8-e588-4225-90b8-51873b70f343"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[ 1.4897, -1.7411]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":[],"metadata":{"id":"4409V3L1txII","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":3,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["import copy \n","\n","class RmDataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.chosen_list = []\n","    self.rejected_list = []\n","    self.end_of_text_token = \"<|endoftext|>\"\n","    \n","    x = 0\n","    train_dataset_copy = copy.deepcopy(train_dataset)\n","    for td in train_dataset_copy:\n","      text1 = td['chosen'].split(\"Assistant:\")[-1]\n","      text2 = td['rejected'].split(\"Assistant:\")[-1]\n","      if len(text1)<500 and len(text2)<500:\n","        self.chosen_list.append(f\"{text1}\")\n","        self.rejected_list.append(f\"{text2}\")\n","\n","  def __len__(self):\n","    return len(self.chosen_list)\n","\n","  def __getitem__(self, index):\n","    chosen_text = self.chosen_list[index]\n","    rejected_text = self.rejected_list[index]\n","\n","    return chosen_text, rejected_text"],"metadata":{"id":"gt0lY90VeIqS","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":3,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["class BERTSequenceClassificationRewardModel(nn.Module):\n","  def __init__(self):\n","    super(BERTSequenceClassificationRewardModel, self).__init__()\n","    self.base = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\").to(device)\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", bos_token='<|startoftext|>', eos_token='<|endoftext|>', padding_side=\"left\")\n","    self.tokenizer.pad_token = '<|endoftext|>'\n","  \n","  def forward(self, prompts):\n","    # prompts include both state(모델에서 주어진 상황: 질문) and action(답변: 모델의 행동 -> 답변) could be raw text of tensor\n","    # ppo 할 때 얘기\n","    print(\"ㄲ\", [prompts[0]])\n","    tokenized=self.tokenizer(prompts, return_tensors='pt', truncation=True, padding=True) # tokenize 후 pytorch tensor를 return 하라는 뜻\n","    print(\"ㄴ\")\n","    input_ids, attention_mask = tokenized.input_ids.to(device), tokenized.attention_mask.to(device)\n","    print(\"ㅇㅇ\", input_ids.shape)\n","    last_hidden_states=self.base(input_ids, attention_mask=attention_mask)\n","    print(\"ㅇㅇss\", last_hidden_states)\n","    \n","    # use final hidden state's EOS embedding token for classification\n","    return last_hidden_states"],"metadata":{"id":"SyTvpRuXeP-W","executionInfo":{"status":"ok","timestamp":1679478770857,"user_tz":-540,"elapsed":2,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["reward_model = BERTSequenceClassificationRewardModel()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GO2_tUwhgtrw","executionInfo":{"status":"ok","timestamp":1679478772992,"user_tz":-540,"elapsed":2137,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"f7c622e0-e5be-411e-8dd6-8b5b5b21fe24"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["class RMTrainer():\n","  def __init__(self, data):\n","    self.train_data=data['train_data']\n","    self.val_data=data['val_data']\n","    # self.test_data=data['test_data']\n","    self.sigmoid = nn.Sigmoid()\n","    #training logs\n","    self.train_logs={ #loss값 기록용\n","        \"loss_history\":[],\n","        \"acc_history\":[],\n","        \"val_acc_history\":[],\n","    }\n","    self.reward_model = reward_model\n","\n","  def plot_logs(self):\n","    loss_history=self.train_logs['loss_history']\n","    acc_history=self.train_logs['acc_history']\n","    plt.figure(figsize=(15,5))\n","    plt.xlabel(\"Iteration\")\n","    plt.ylabel(\"Loss\")\n","    plt.plot(loss_history, \"b-\")\n","    plt.show()\n","\n","    plt.figure(figsize=(15,5))\n","    plt.xlabel(\"Iteration\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.plot(acc_history, \"r-\")\n","    plt.show()\n","\n","  def get_loss(self, chosens, rejecteds):\n","    # 전부 다 배치로 처리된다는 점을 고려해야한다.\n","    batch_size = len(rejecteds)\n","    correct_count=0\n","    print(11, chosens)\n","    \n","    chosen_rewards, eos = self.reward_model(chosens) # should be +\n","    print(22)\n","    rejecteds_rewards, eos = self.reward_model(rejecteds) # should be -\n","\n","    loss = torch.FloatTensor([0]).to(device)\n","    print(33)\n","\n","    for idx, rejec_reward in enumerate(rejecteds_rewards):\n","      chosen_reward = chosen_rewards[idx]\n","      diff = chosen_reward - rejec_reward # this should be +1,    -1 is the worst\n","      loss = loss-torch.log(self.sigmoid(diff))\n","      correct_count+=(chosen_reward.item()>rejec_reward.item()) # for count\n","    print(44)\n","\n","    loss = loss/len(rejecteds_rewards)\n","    accuracy = correct_count/len(rejecteds_rewards)\n","    return loss, accuracy\n","\n","  def train(self, num_epochs, batch_size, lr, reg):\n","    train_loader = torch.utils.data.DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n","    rm_optimizer = optim.AdamW(self.reward_model.parameters(), lr=lr, weight_decay=reg)\n","    print(1)\n","    \n","    for epoch in range(num_epochs):\n","      print(5)\n","      train_acc = 0\n","      for idx, data in tqdm(enumerate(train_loader)):\n","        print(6)\n","        self.reward_model.train() # train 상태로 둔다.\n","        print(2)\n","        chosens, rejecteds = data\n","        loss, acc = self.get_loss(chosens, rejecteds)\n","        print(3)\n","\n","        # weight update\n","        rm_optimizer.zero_grad()\n","        loss.backward()\n","        rm_optimizer.step()\n","\n","        # tran_acc update\n","        print(4)\n","        train_acc = (train_acc*idx + acc)/(idx+1)\n","        self.train_logs['loss_history'].append(loss.item())\n","        self.train_logs['acc_history'].append(train_acc)\n","\n","        if idx%200 == 0:\n","          self.plot_logs()\n","          print(f\"Loss: {np.mean(self.train_logs['loss_history'])}, all_acc : {train_acc}\")\n","      val_acc=self.validate()\n","      print(\"validation accuracy : \", val_acc)"],"metadata":{"id":"-LpTpaQLowxM","executionInfo":{"status":"ok","timestamp":1679478772993,"user_tz":-540,"elapsed":3,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["reward_dataset = RmDataset()\n","dataset_size = len(reward_dataset)\n","\n","train_size = int(dataset_size * 0.8)\n","validation_size = dataset_size - train_size\n","# test_size = dataset_size - train_size - validation_size\n","\n","train_dataset, validation_dataset = torch.utils.data.random_split(reward_dataset, [train_size, validation_size])\n","\n","splited_data = {\"train_data\":train_dataset, \"val_data\":validation_dataset}"],"metadata":{"id":"ElOVC4_TpDFj","executionInfo":{"status":"ok","timestamp":1679478779591,"user_tz":-540,"elapsed":6600,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["anth = RMTrainer(splited_data)"],"metadata":{"id":"s1wR-upwpGff","executionInfo":{"status":"ok","timestamp":1679478783001,"user_tz":-540,"elapsed":725,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["setting = {\n","    \"num_epochs\":4,\n","    \"batch_size\":1,\n","    \"lr\":0.00012, # learning rate\n","    \"reg\":0.008,\n","}"],"metadata":{"id":"73PbkuQ8pIoz","executionInfo":{"status":"ok","timestamp":1679478783273,"user_tz":-540,"elapsed":3,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["anth.train(setting['num_epochs'], setting['batch_size'], setting['lr'], setting['reg'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"id":"W5cXX_KOpK6Z","executionInfo":{"status":"error","timestamp":1679478784158,"user_tz":-540,"elapsed":289,"user":{"displayName":"김호진","userId":"05277196388601250512"}},"outputId":"826bd5cb-4736-4ea6-e0ec-fb4671b2f31b"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","5\n"]},{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["6\n","2\n","11 (' Hello, I’m your virtual assistant. Are you looking for Rick Springfield albums? Here’s the list:',)\n","ㄲ [' Hello, I’m your virtual assistant. Are you looking for Rick Springfield albums? Here’s the list:']\n","ㄴ\n","ㅇㅇ torch.Size([1, 25])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-87aa64603881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-67-8bae02cb254b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, batch_size, lr, reg)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mchosens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrejecteds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrejecteds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-67-8bae02cb254b>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, chosens, rejecteds)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mchosen_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# should be +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mrejecteds_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrejecteds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# should be -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"V9zo4EB149F5","executionInfo":{"status":"aborted","timestamp":1679478736039,"user_tz":-540,"elapsed":6,"user":{"displayName":"김호진","userId":"05277196388601250512"}}},"execution_count":null,"outputs":[]}]}